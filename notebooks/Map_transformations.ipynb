{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import habitat\n",
    "from habitat.utils.visualizations import maps\n",
    "from habitat.utils.visualizations.utils import images_to_video\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from habitat_sim.utils import d3_40_colors_rgb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_sample(rgb_obs, region_maps):\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGB\")\n",
    "    \n",
    "    arr = [rgb_img]\n",
    "    titles = ['rgb']\n",
    "    \n",
    "    for room_type, room_map in region_maps.items():\n",
    "        titles.append(room_type)\n",
    "        room_img = Image.fromarray(room_map.astype('uint8'))\n",
    "        arr.append(room_img)\n",
    "    \n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 6, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()\n",
    "    \n",
    "def display_sample(rgb_obs, region_maps, top_down):\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGB\")\n",
    "    \n",
    "    arr = [rgb_img]\n",
    "    titles = ['rgb']\n",
    "    \n",
    "    for room_type, room_map in region_maps.items():\n",
    "        titles.append(room_type)\n",
    "        room_img = Image.fromarray(room_map.astype('uint8'))\n",
    "        arr.append(room_img)\n",
    "    \n",
    "    arr.append(top_down)\n",
    "    titles.append('top_down')\n",
    "    \n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 7, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-19 14:42:00,918 initializing sim Sim-v0\n",
      "I0719 14:42:00.998184 8003 simulator.py:78] Loaded navmesh /private/home/medhini/navigation-analysis-habitat/habitat-api/data/scene_datasets/mp3d/2azQ1b91cZZ/2azQ1b91cZZ.navmesh\n",
      "2019-07-19 14:42:12,628 initializing task Nav-v0\n"
     ]
    }
   ],
   "source": [
    "config = habitat.get_config(config_paths='../configs/tasks/roomnav_mp3d_new.yaml')\n",
    "config.defrost()\n",
    "config.DATASET.DATA_PATH = '../data/datasets/roomnav/mp3d/v1/val/val.json.gz'\n",
    "config.DATASET.SCENES_DIR = '../data/scene_datasets/'\n",
    "config.SIMULATOR.AGENT_0.SENSORS = ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']\n",
    "config.SIMULATOR.SEMANTIC_SENSOR.WIDTH = 256\n",
    "config.SIMULATOR.SEMANTIC_SENSOR.HEIGHT = 256\n",
    "config.SIMULATOR.TURN_ANGLE = 90\n",
    "config.freeze()\n",
    "\n",
    "env = habitat.Env(config=config)\n",
    "env.episodes = random.sample(env.episodes, 2)\n",
    "\n",
    "action_mapping = {\n",
    "    0: 'stop',\n",
    "    1: 'move_forward',\n",
    "    2: 'turn left',\n",
    "    3: 'turn right'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_top_down_map(info, heading, output_size):\n",
    "    top_down_map = maps.colorize_topdown_map(info[\"top_down_map\"][\"map\"])\n",
    "    original_map_size = top_down_map.shape[:2]\n",
    "    map_scale = np.array(\n",
    "        (1, original_map_size[1] * 1.0 / original_map_size[0])\n",
    "    )\n",
    "    new_map_size = np.round(output_size * map_scale).astype(np.int32)\n",
    "    # OpenCV expects w, h but map size is in h, w\n",
    "    top_down_map = cv2.resize(top_down_map, (new_map_size[1], new_map_size[0]))\n",
    "\n",
    "    map_agent_pos = info[\"top_down_map\"][\"agent_map_coord\"]\n",
    "    map_agent_pos = np.round(\n",
    "        map_agent_pos * new_map_size / original_map_size\n",
    "    ).astype(np.int32)\n",
    "    top_down_map = maps.draw_agent(\n",
    "        top_down_map,\n",
    "        map_agent_pos,\n",
    "        heading - np.pi / 2,\n",
    "        agent_radius_px=top_down_map.shape[0] / 40,\n",
    "    )\n",
    "    return top_down_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_maps(scene, T_world_curr, crop_size, room_types, scale):\n",
    "    scene = env.sim.semantic_annotations()\n",
    "    \n",
    "    scene_bounds = np.array([scene.aabb.center[0] - scene.aabb.sizes[0]/2, \n",
    "                             scene.aabb.center[1] - scene.aabb.sizes[1]/2,\n",
    "                             scene.aabb.center[2] + scene.aabb.sizes[2]/2,\n",
    "                             scene.aabb.center[0] + scene.aabb.sizes[0]/2,\n",
    "                             scene.aabb.center[1] + scene.aabb.sizes[1]/2,\n",
    "                             scene.aabb.center[2] - scene.aabb.sizes[2]/2\n",
    "                            ])\n",
    "    \n",
    "    T_world_image = np.eye(3)\n",
    "    T_world_image[0,2] = abs(min(0, scene_bounds[0]))\n",
    "    T_world_image[1,2] = abs(min(0, scene_bounds[2]))\n",
    "    \n",
    "    if scale:\n",
    "        T_world_image[0,0] = math.floor(100/abs(scene.aabb.sizes[0]))\n",
    "        T_world_image[1,1] = math.floor(100/abs(scene.aabb.sizes[2]))\n",
    "    \n",
    "    region_maps = {}\n",
    "    \n",
    "    images = {}\n",
    "    \n",
    "    for room_type in room_types:\n",
    "        if not scale:\n",
    "            images[room_type] = np.zeros((math.ceil(abs(scene.aabb.sizes[0])), math.ceil(abs(scene.aabb.sizes[2]))))\n",
    "        else:\n",
    "            images[room_type] = np.zeros((100,100))\n",
    "        \n",
    "    for region in scene.levels[0].regions:\n",
    "        if region.category.name() in room_types:\n",
    "            region_center = np.array([region.aabb.center[0], region.aabb.center[1], region.aabb.center[2], 1])\n",
    "            print('T_world_curr: ', T_world_curr)\n",
    "            print('Old center: ', region_center)\n",
    "            \n",
    "            i,j,k,_ = T_world_curr @ region_center\n",
    "            \n",
    "            print('New center: ', [i,j,k])\n",
    "            \n",
    "            sys.exit(0)\n",
    "            \n",
    "            region_min = np.array([i-region.aabb.sizes[0]/2, k+region.aabb.sizes[2]/2, 1.0])\n",
    "            region_max = np.array([i+region.aabb.sizes[0]/2, k-region.aabb.sizes[2]/2, 1.0])\n",
    "            \n",
    "            region_min_t = T_world_image @ region_min\n",
    "            region_max_t = T_world_image @ region_max\n",
    "            \n",
    "            x1 = math.ceil(region_min_t[0])\n",
    "            x2 = math.ceil(region_max_t[0])\n",
    "            y1 = math.ceil(region_min_t[1])\n",
    "            y2 = math.ceil(region_max_t[1])\n",
    "            \n",
    "            if not scale:\n",
    "                images[region.category.name()][x1:x2,y1:y2] = 255\n",
    "            \n",
    "            \n",
    "    for room_type in room_types:\n",
    "        img = images[room_type]\n",
    "        \n",
    "#         print(room_type)\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        \n",
    "        img_padded = np.zeros((1000,1000))\n",
    "        x1 = math.ceil((1000 - img.shape[0])/2)\n",
    "        x2 = math.ceil((1000 + img.shape[0])/2)\n",
    "        y1 = math.ceil((1000 - img.shape[1])/2)\n",
    "        y2 = math.ceil((1000 + img.shape[1])/2)\n",
    "        img_padded[x1:x2,y1:y2] = img\n",
    "        \n",
    "        x1 = math.ceil((1000 - crop_size)/2)\n",
    "        x2 = math.ceil((1000 + crop_size)/2)\n",
    "        y1 = math.ceil((1000 - crop_size)/2)\n",
    "        y2 = math.ceil((1000 + crop_size)/2)\n",
    "        cropped_img = img_padded[x1:x2, y1:y2]\n",
    "        \n",
    "        region_maps[room_type] = np.asarray(cropped_img)\n",
    "        \n",
    "    return region_maps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 15:45:21.445246 8003 simulator.py:78] Loaded navmesh /private/home/medhini/navigation-analysis-habitat/habitat-api/data/scene_datasets/mp3d/zsNo4HB9uLZ/zsNo4HB9uLZ.navmesh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Rotation:  [[ 0.86095453  0.          0.50868192]\n",
      " [ 0.          1.          0.        ]\n",
      " [-0.50868192  0.          0.86095453]] Start Position:  [-9.55895221 -0.17162801 13.85466736]\n",
      "T_world_curr:  [[ 0.86095453  0.          0.50868192 -9.55895221]\n",
      " [ 0.          1.          0.         -0.17162801]\n",
      " [-0.50868192  0.          0.86095453 13.85466736]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Old center:  [-0.40688503  1.39056039 -6.07064915  1.        ]\n",
      "New center:  [-12.997291158649745, 1.2189323753118515, 8.835089514725858]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "actions = [2,2,2,2]\n",
    "crop_size = 50\n",
    "room_types = ['kitchen', 'bedroom', 'bathroom', 'dining room', 'living room']\n",
    "SCALE = False\n",
    "\n",
    "for i in range(len(env.episodes)):\n",
    "    observations = env.reset()\n",
    "    \n",
    "    rotation = quaternion.as_rotation_matrix(observations['gps_and_compass'].rot)\n",
    "    translation = observations['gps_and_compass'].trans\n",
    "    print('Start Rotation: ', rotation, 'Start Position: ', translation)\n",
    "    \n",
    "    T_world_curr = np.eye(4)\n",
    "    T_world_curr[:3,:3] = rotation\n",
    "    T_world_curr[:3,3] = translation\n",
    "    \n",
    "    scene = env.sim.semantic_annotations()\n",
    "    region_maps = construct_maps(scene, T_world_curr, crop_size, room_types, SCALE)\n",
    "    display_sample(observations['rgb'], region_maps)\n",
    "    \n",
    "    images = []\n",
    "    count_steps = 0\n",
    "    for action in actions:\n",
    "        observations, _,  _, info = env.step(action)\n",
    "        \n",
    "        rotatation = quaternion.as_rotation_matrix(observations['gps_and_compass'].rot)\n",
    "        translation = observations['gps_and_compass'].trans\n",
    "        print('Rotation: ', rotatation, 'Position: ', translation)\n",
    "        \n",
    "        T_world_curr = np.eye(4)\n",
    "        T_world_curr[:3,:3] = rotation\n",
    "        T_world_curr[:3,3] = translation\n",
    "    \n",
    "        #Align region maps with new position of agent\n",
    "        region_maps = construct_maps(scene, T_world_curr, crop_size, room_types, SCALE)\n",
    "        \n",
    "        im = observations[\"rgb\"]\n",
    "        top_down_map = draw_top_down_map(\n",
    "            info, observations[\"heading\"], im.shape[0]\n",
    "        )\n",
    "        output_im = np.concatenate((im, top_down_map), axis=1)\n",
    "        images.append(output_im)\n",
    "\n",
    "        display_sample(observations['rgb'], region_maps, output_im)\n",
    "        \n",
    "        count_steps += 1\n",
    "        if env.episode_over:\n",
    "            print('EPISODE OVER!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.linspace(0,99,100), np.linspace(0,99,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(scene_maps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = np.zeros((500,500),dtype=np.uint8)\n",
    "map[:,:] = 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array([[1,0,100],[0,1,100],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = scene_maps[0]\n",
    "map = np.zeros((200,200),dtype=np.float32)\n",
    "map[:,:] = 255.0\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(map)\n",
    "\n",
    "for i, row in enumerate(img):\n",
    "    for j, col in enumerate(row):\n",
    "        pixel_data = img[i,j]\n",
    "        input_coords = np.array([i,j,1])\n",
    "        i_out, j_out, _ = T @ input_coords\n",
    "        if i_out < map.shape[0] and j_out < map.shape[1]:\n",
    "            map[i_out, j_out] = pixel_data\n",
    "        \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map.rotate(270))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map.rotate(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map.rotate(180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map.rotate(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(floor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = scene_maps[0]\n",
    "img = np.asarray(img)\n",
    "img[:20,:20] = 0.0\n",
    "img = Image.fromarray(img.astype('uint8'))\n",
    "a = 1\n",
    "b = 0\n",
    "c = 30 #left/right (i.e. 5/-5)\n",
    "d = 0\n",
    "e = 1\n",
    "f = 30 #up/down (i.e. 5/-5)\n",
    "img = img.transform(img.size, Image.AFFINE, (a, b, c, d, e, f))\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.rotate(45)\n",
    "display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
